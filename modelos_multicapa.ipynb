{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import (Model, \n",
    "                                     load_model, \n",
    "                                     Sequential)\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.metrics import (accuracy_score, \n",
    "                             precision_score, \n",
    "                             recall_score,\n",
    "                             confusion_matrix)\n",
    "\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "from table_data_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n",
      "Dispositivo actual: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "devices = tf.config.list_physical_devices('GPU')\n",
    "for device in devices:\n",
    "    print(device)\n",
    "\n",
    "# Verificar qué dispositivo está siendo utilizado actualmente\n",
    "print(\"Dispositivo actual:\", tf.test.gpu_device_name() if tf.test.gpu_device_name() else \"CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Recording</th>\n",
       "      <th>Status</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Jitter_rel</th>\n",
       "      <th>Jitter_abs</th>\n",
       "      <th>Jitter_RAP</th>\n",
       "      <th>Jitter_PPQ</th>\n",
       "      <th>Shim_loc</th>\n",
       "      <th>Shim_dB</th>\n",
       "      <th>...</th>\n",
       "      <th>Delta3</th>\n",
       "      <th>Delta4</th>\n",
       "      <th>Delta5</th>\n",
       "      <th>Delta6</th>\n",
       "      <th>Delta7</th>\n",
       "      <th>Delta8</th>\n",
       "      <th>Delta9</th>\n",
       "      <th>Delta10</th>\n",
       "      <th>Delta11</th>\n",
       "      <th>Delta12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CONT-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.25546</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.001467</td>\n",
       "      <td>0.001673</td>\n",
       "      <td>0.030256</td>\n",
       "      <td>0.26313</td>\n",
       "      <td>...</td>\n",
       "      <td>1.407701</td>\n",
       "      <td>1.417218</td>\n",
       "      <td>1.380352</td>\n",
       "      <td>1.420670</td>\n",
       "      <td>1.451240</td>\n",
       "      <td>1.440295</td>\n",
       "      <td>1.403678</td>\n",
       "      <td>1.405495</td>\n",
       "      <td>1.416705</td>\n",
       "      <td>1.354610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CONT-01</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.36964</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.001932</td>\n",
       "      <td>0.002245</td>\n",
       "      <td>0.023146</td>\n",
       "      <td>0.20217</td>\n",
       "      <td>...</td>\n",
       "      <td>1.331232</td>\n",
       "      <td>1.227338</td>\n",
       "      <td>1.213377</td>\n",
       "      <td>1.352739</td>\n",
       "      <td>1.354242</td>\n",
       "      <td>1.365692</td>\n",
       "      <td>1.322870</td>\n",
       "      <td>1.314549</td>\n",
       "      <td>1.318999</td>\n",
       "      <td>1.323508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CONT-01</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.23514</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.001353</td>\n",
       "      <td>0.001546</td>\n",
       "      <td>0.019338</td>\n",
       "      <td>0.16710</td>\n",
       "      <td>...</td>\n",
       "      <td>1.412304</td>\n",
       "      <td>1.324674</td>\n",
       "      <td>1.276088</td>\n",
       "      <td>1.429634</td>\n",
       "      <td>1.455996</td>\n",
       "      <td>1.368882</td>\n",
       "      <td>1.438053</td>\n",
       "      <td>1.388910</td>\n",
       "      <td>1.305469</td>\n",
       "      <td>1.305402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CONT-02</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.29320</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.001105</td>\n",
       "      <td>0.001444</td>\n",
       "      <td>0.024716</td>\n",
       "      <td>0.20892</td>\n",
       "      <td>...</td>\n",
       "      <td>1.501200</td>\n",
       "      <td>1.534170</td>\n",
       "      <td>1.323993</td>\n",
       "      <td>1.496442</td>\n",
       "      <td>1.472926</td>\n",
       "      <td>1.643177</td>\n",
       "      <td>1.551286</td>\n",
       "      <td>1.638346</td>\n",
       "      <td>1.604008</td>\n",
       "      <td>1.621456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CONT-02</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.23075</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.001073</td>\n",
       "      <td>0.001404</td>\n",
       "      <td>0.013119</td>\n",
       "      <td>0.11607</td>\n",
       "      <td>...</td>\n",
       "      <td>1.508468</td>\n",
       "      <td>1.334511</td>\n",
       "      <td>1.610694</td>\n",
       "      <td>1.685021</td>\n",
       "      <td>1.417614</td>\n",
       "      <td>1.574895</td>\n",
       "      <td>1.640088</td>\n",
       "      <td>1.533666</td>\n",
       "      <td>1.297536</td>\n",
       "      <td>1.382023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID  Recording  Status  Gender  Jitter_rel  Jitter_abs  Jitter_RAP  \\\n",
       "0  CONT-01          1       0       1     0.25546    0.000015    0.001467   \n",
       "1  CONT-01          2       0       1     0.36964    0.000022    0.001932   \n",
       "2  CONT-01          3       0       1     0.23514    0.000013    0.001353   \n",
       "3  CONT-02          1       0       0     0.29320    0.000017    0.001105   \n",
       "4  CONT-02          2       0       0     0.23075    0.000015    0.001073   \n",
       "\n",
       "   Jitter_PPQ  Shim_loc  Shim_dB  ...    Delta3    Delta4    Delta5    Delta6  \\\n",
       "0    0.001673  0.030256  0.26313  ...  1.407701  1.417218  1.380352  1.420670   \n",
       "1    0.002245  0.023146  0.20217  ...  1.331232  1.227338  1.213377  1.352739   \n",
       "2    0.001546  0.019338  0.16710  ...  1.412304  1.324674  1.276088  1.429634   \n",
       "3    0.001444  0.024716  0.20892  ...  1.501200  1.534170  1.323993  1.496442   \n",
       "4    0.001404  0.013119  0.11607  ...  1.508468  1.334511  1.610694  1.685021   \n",
       "\n",
       "     Delta7    Delta8    Delta9   Delta10   Delta11   Delta12  \n",
       "0  1.451240  1.440295  1.403678  1.405495  1.416705  1.354610  \n",
       "1  1.354242  1.365692  1.322870  1.314549  1.318999  1.323508  \n",
       "2  1.455996  1.368882  1.438053  1.388910  1.305469  1.305402  \n",
       "3  1.472926  1.643177  1.551286  1.638346  1.604008  1.621456  \n",
       "4  1.417614  1.574895  1.640088  1.533666  1.297536  1.382023  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importamos los datos\n",
    "datos_pacientes = pd.read_csv(\"ReplicatedAcousticFeatures-ParkinsonDatabase.csv\")\n",
    "\n",
    "datos_pacientes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_dec_gini_vars = [\"HNR05\",\"HNR15\",\"HNR25\",\"HNR35\",\"HNR38\",\"MFCC0\",\"MFCC3\",\"MFCC4\",\"MFCC5\",\"MFCC6\",\"MFCC7\",\"MFCC8\",\"MFCC9\",\"MFCC10\",\"MFCC11\",\"MFCC12\",\"Delta0\",\"Delta1\",\"Delta2\",\"Delta3\",\"Delta5\",\"Delta7\",\"Delta9\",\"Delta10\",\"Delta11\",\"Delta12\"]\n",
    "subset_dec_acc_vars = [\"HNR05\", \"HNR15\", \"HNR25\", \"HNR35\", \"HNR38\", \"PPE\", \"MFCC3\", \"MFCC4\", \"MFCC5\", \"MFCC6\", \"MFCC7\", \"MFCC8\", \"MFCC9\", \"MFCC10\", \"MFCC11\", \"MFCC12\", \"Delta0\", \"Delta1\", \"Delta2\", \"Delta3\", \"Delta4\", \"Delta5\", \"Delta9\", \"Delta10\", \"Delta11\", \"Delta12\"]\n",
    "subset_imp_xgb_vars = [\"Delta0\", \"HNR38\", \"MFCC4\", \"PPE\", \"HNR35\", \"GNE\", \"Delta11\", \"MFCC5\", \"Delta5\", \"MFCC3\", \"RPDE\", \"MFCC10\", \"Shim_loc\", \"Shi_APQ11\", \"MFCC9\", \"Delta7\", \"MFCC2\", \"MFCC6\", \"MFCC11\", \"MFCC1\", \"DFA\", \"Delta12\", \"Shim_APQ5\", \"MFCC7\", \"Delta6\"]\n",
    "subset_interseccion_vars = [\"HNR35\", \"HNR38\", \"MFCC3\", \"MFCC4\", \"MFCC5\", \"MFCC6\", \"MFCC7\", \"MFCC9\", \"MFCC10\", \"MFCC11\", \"Delta0\", \"Delta5\", \"Delta11\", \"Delta12\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sex = np.array(datos_pacientes[['ID', 'Gender']].drop_duplicates()['Gender'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Primer conjunto\n",
    "subset_dec_gini_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************** iteracion 1 **********************\n",
      "********************** iteracion 2 **********************\n",
      "********************** iteracion 3 **********************\n",
      "********************** iteracion 4 **********************\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001A418D61FC0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "********************** iteracion 5 **********************\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001A418D63F40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "********************** iteracion 6 **********************\n",
      "********************** iteracion 7 **********************\n",
      "********************** iteracion 8 **********************\n",
      "********************** iteracion 9 **********************\n",
      "********************** iteracion 10 **********************\n",
      "********************** iteracion 11 **********************\n",
      "********************** iteracion 12 **********************\n",
      "********************** iteracion 13 **********************\n",
      "********************** iteracion 14 **********************\n",
      "********************** iteracion 15 **********************\n",
      "********************** iteracion 16 **********************\n",
      "********************** iteracion 17 **********************\n",
      "********************** iteracion 18 **********************\n",
      "********************** iteracion 19 **********************\n",
      "********************** iteracion 20 **********************\n",
      "********************** iteracion 21 **********************\n",
      "********************** iteracion 22 **********************\n",
      "********************** iteracion 23 **********************\n",
      "********************** iteracion 24 **********************\n",
      "********************** iteracion 25 **********************\n",
      "********************** iteracion 26 **********************\n",
      "********************** iteracion 27 **********************\n",
      "********************** iteracion 28 **********************\n",
      "********************** iteracion 29 **********************\n",
      "********************** iteracion 30 **********************\n",
      "********************** iteracion 31 **********************\n",
      "********************** iteracion 32 **********************\n",
      "********************** iteracion 33 **********************\n",
      "********************** iteracion 34 **********************\n",
      "********************** iteracion 35 **********************\n",
      "********************** iteracion 36 **********************\n",
      "********************** iteracion 37 **********************\n",
      "********************** iteracion 38 **********************\n",
      "********************** iteracion 39 **********************\n",
      "********************** iteracion 40 **********************\n",
      "********************** iteracion 41 **********************\n",
      "********************** iteracion 42 **********************\n",
      "********************** iteracion 43 **********************\n",
      "********************** iteracion 44 **********************\n",
      "********************** iteracion 45 **********************\n",
      "********************** iteracion 46 **********************\n",
      "********************** iteracion 47 **********************\n",
      "********************** iteracion 48 **********************\n",
      "********************** iteracion 49 **********************\n",
      "********************** iteracion 50 **********************\n",
      "********************** iteracion 51 **********************\n",
      "********************** iteracion 52 **********************\n",
      "********************** iteracion 53 **********************\n",
      "********************** iteracion 54 **********************\n",
      "********************** iteracion 55 **********************\n",
      "********************** iteracion 56 **********************\n",
      "********************** iteracion 57 **********************\n",
      "********************** iteracion 58 **********************\n",
      "********************** iteracion 59 **********************\n",
      "********************** iteracion 60 **********************\n",
      "********************** iteracion 61 **********************\n",
      "********************** iteracion 62 **********************\n",
      "********************** iteracion 63 **********************\n",
      "********************** iteracion 64 **********************\n",
      "********************** iteracion 65 **********************\n",
      "********************** iteracion 66 **********************\n",
      "********************** iteracion 67 **********************\n",
      "********************** iteracion 68 **********************\n",
      "********************** iteracion 69 **********************\n",
      "********************** iteracion 70 **********************\n",
      "********************** iteracion 71 **********************\n",
      "********************** iteracion 72 **********************\n",
      "********************** iteracion 73 **********************\n",
      "********************** iteracion 74 **********************\n",
      "********************** iteracion 75 **********************\n",
      "********************** iteracion 76 **********************\n",
      "********************** iteracion 77 **********************\n",
      "********************** iteracion 78 **********************\n",
      "********************** iteracion 79 **********************\n",
      "********************** iteracion 80 **********************\n"
     ]
    }
   ],
   "source": [
    "# definimos las variables que vamos a utilizar en el modelo\n",
    "ids = datos_pacientes['ID'].to_numpy()\n",
    "X = datos_pacientes.drop(columns=['ID', 'Recording', 'Status', 'Gender'])\n",
    "X = X[subset_dec_gini_vars]\n",
    "y = np.array(datos_pacientes['Status'])\n",
    "\n",
    "# definimos el leave one group out\n",
    "logo = LeaveOneGroupOut()\n",
    "logo.get_n_splits(X, y, groups=ids)\n",
    "\n",
    "# guardamos los valores de las diferentes métricas\n",
    "test_metrics = np.zeros(80) # el 80 es por el numero de grupos que hay\n",
    "\n",
    "y_group_true = np.zeros(80)\n",
    "y_group_pred = np.zeros(80)\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(logo.split(X, y, groups=ids)):\n",
    "\n",
    "    tf.random.set_seed(i)\n",
    "\n",
    "    X_train = X.iloc[train_index, :]; X_test = X.iloc[test_index, :]\n",
    "    y_train = y[train_index]; y_test = y[test_index]\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    modelo = model()\n",
    "\n",
    "    trained_model, _ = compile_fit_model(modelo, X_train=X_train_scaled, y_train=y_train)\n",
    "\n",
    "    y_test_preds =  model_evaluate(model=trained_model, X_test=X_test_scaled)\n",
    "\n",
    "    y_group_pred[i] = np.argmax(np.bincount(y_test_preds, minlength = 2))\n",
    "\n",
    "    y_group_true[i] = np.argmax(np.bincount(y_test, minlength = 2))\n",
    "\n",
    "    # metricas sin considerar grupos\n",
    "    test_metrics[i] = accuracy_score(y_pred=y_test_preds, \n",
    "                                        y_true=y_test)\n",
    "                        #  precision_score(y_pred=y_test_preds, \n",
    "                        #                  y_true=y_test),\n",
    "                        #  recall_score(y_pred=y_test_preds, \n",
    "                        #               y_true=y_test),\n",
    "                        # specificity_score(y_pred=y_test_preds, \n",
    "                        #                    y_true=y_test)\n",
    "                                        #    ]\n",
    "    print(f\"********************** iteracion {i + 1} **********************\")\n",
    "    \n",
    "    # limpiamos la sesion\n",
    "    del(modelo, trained_model, X_train, y_train, X_test, y_test, X_train_scaled, X_test_scaled)\n",
    "    tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.775\n",
      "0.775\n",
      "0.7894736842105263\n",
      "0.75\n",
      "0.8\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(y_group_true == y_group_pred))\n",
    "print(accuracy_score(y_pred=y_group_pred, y_true=y_group_true))\n",
    "print(precision_score(y_pred=y_group_pred, y_true=y_group_true))\n",
    "print(recall_score(y_pred=y_group_pred, y_true=y_group_true))\n",
    "print(specificity_score(y_pred=y_group_pred, y_true=y_group_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7083333333333334\n",
      "0.875\n",
      "0.8\n",
      "0.7777777777777778\n",
      "0.6153846153846154\n",
      "1.0\n",
      "0.8181818181818182\n",
      "0.7777777777777778\n"
     ]
    }
   ],
   "source": [
    "hombres = y_group_true[np.where(sex == 0)]\n",
    "mujeres = y_group_true[np.where(sex == 1)]\n",
    "\n",
    "hombres_preds = y_group_pred[np.where(sex == 0)]\n",
    "mujeres_preds = y_group_pred[np.where(sex == 1)]\n",
    "\n",
    "print(accuracy_score(y_pred=hombres_preds, y_true=hombres))\n",
    "print(accuracy_score(y_pred=mujeres_preds,  y_true=mujeres))\n",
    "print(precision_score(y_pred=hombres_preds, y_true=hombres))\n",
    "print(precision_score(y_pred=mujeres_preds, y_true=mujeres))\n",
    "print(recall_score(y_pred=hombres_preds, y_true=hombres))\n",
    "print(recall_score(y_pred=mujeres_preds, y_true=mujeres))\n",
    "print(specificity_score(y_pred=hombres_preds, y_true=hombres))\n",
    "print(specificity_score(y_pred=mujeres_preds, y_true=mujeres))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tercer conjunto\n",
    "subset_imp_xgb_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definimos las variables que vamos a utilizar en el modelo\n",
    "ids = datos_pacientes['ID'].to_numpy()\n",
    "X = datos_pacientes.drop(columns=['ID', 'Recording', 'Status', 'Gender'])\n",
    "X = X[subset_imp_xgb_vars]\n",
    "y = np.array(datos_pacientes['Status'])\n",
    "\n",
    "# definimos el leave one group out\n",
    "logo = LeaveOneGroupOut()\n",
    "logo.get_n_splits(X, y, groups=ids)\n",
    "\n",
    "# guardamos los valores de las diferentes métricas\n",
    "test_metrics = np.zeros(80) # el 80 es por el numero de grupos que hay\n",
    "\n",
    "y_group_true = np.zeros(80)\n",
    "y_group_pred = np.zeros(80)\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(logo.split(X, y, groups=ids)):\n",
    "\n",
    "    tf.random.set_seed(i)\n",
    "\n",
    "    X_train = X.iloc[train_index, :]; X_test = X.iloc[test_index, :]\n",
    "    y_train = y[train_index]; y_test = y[test_index]\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    modelo = model()\n",
    "\n",
    "    trained_model, _ = compile_fit_model(modelo, X_train=X_train_scaled, y_train=y_train)\n",
    "\n",
    "    y_test_preds =  model_evaluate(model=trained_model, X_test=X_test_scaled)\n",
    "\n",
    "    y_group_pred[i] = np.argmax(np.bincount(y_test_preds, minlength = 2))\n",
    "\n",
    "    y_group_true[i] = np.argmax(np.bincount(y_test, minlength = 2))\n",
    "\n",
    "    # metricas sin considerar grupos\n",
    "    test_metrics[i] = accuracy_score(y_pred=y_test_preds, \n",
    "                                        y_true=y_test)\n",
    "                        #  precision_score(y_pred=y_test_preds, \n",
    "                        #                  y_true=y_test),\n",
    "                        #  recall_score(y_pred=y_test_preds, \n",
    "                        #               y_true=y_test),\n",
    "                        # specificity_score(y_pred=y_test_preds, \n",
    "                        #                    y_true=y_test)\n",
    "                                        #    ]\n",
    "    print(f\"********************** iteracion {i + 1} **********************\")\n",
    "    \n",
    "    # limpiamos la sesion\n",
    "    del(modelo, trained_model, X_train, y_train, X_test, y_test, X_train_scaled, X_test_scaled)\n",
    "    tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(y_group_true == y_group_pred))\n",
    "print(accuracy_score(y_pred=y_group_pred, y_true=y_group_true))\n",
    "print(precision_score(y_pred=y_group_pred, y_true=y_group_true))\n",
    "print(recall_score(y_pred=y_group_pred, y_true=y_group_true))\n",
    "print(specificity_score(y_pred=y_group_pred, y_true=y_group_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "hombres = y_group_true[np.where(sex == 0)]\n",
    "mujeres = y_group_true[np.where(sex == 1)]\n",
    "\n",
    "hombres_preds = y_group_pred[np.where(sex == 0)]\n",
    "mujeres_preds = y_group_pred[np.where(sex == 1)]\n",
    "\n",
    "print(accuracy_score(y_pred=hombres_preds, y_true=hombres))\n",
    "print(accuracy_score(y_pred=mujeres_preds,  y_true=mujeres))\n",
    "print(precision_score(y_pred=hombres_preds, y_true=hombres))\n",
    "print(precision_score(y_pred=mujeres_preds, y_true=mujeres))\n",
    "print(recall_score(y_pred=hombres_preds, y_true=hombres))\n",
    "print(recall_score(y_pred=mujeres_preds, y_true=mujeres))\n",
    "print(specificity_score(y_pred=hombres_preds, y_true=hombres))\n",
    "print(specificity_score(y_pred=mujeres_preds, y_true=mujeres))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cuarto conjunto\n",
    "subset_interseccion_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definimos las variables que vamos a utilizar en el modelo\n",
    "ids = datos_pacientes['ID'].to_numpy()\n",
    "X = datos_pacientes.drop(columns=['ID', 'Recording', 'Status', 'Gender'])\n",
    "X = X[subset_interseccion_vars]\n",
    "y = np.array(datos_pacientes['Status'])\n",
    "\n",
    "# definimos el leave one group out\n",
    "logo = LeaveOneGroupOut()\n",
    "logo.get_n_splits(X, y, groups=ids)\n",
    "\n",
    "# guardamos los valores de las diferentes métricas\n",
    "test_metrics = np.zeros(80) # el 80 es por el numero de grupos que hay\n",
    "\n",
    "y_group_true = np.zeros(80)\n",
    "y_group_pred = np.zeros(80)\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(logo.split(X, y, groups=ids)):\n",
    "\n",
    "    tf.random.set_seed(i)\n",
    "\n",
    "    X_train = X.iloc[train_index, :]; X_test = X.iloc[test_index, :]\n",
    "    y_train = y[train_index]; y_test = y[test_index]\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    modelo = model()\n",
    "\n",
    "    trained_model, _ = compile_fit_model(modelo, X_train=X_train_scaled, y_train=y_train)\n",
    "\n",
    "    y_test_preds =  model_evaluate(model=trained_model, X_test=X_test_scaled)\n",
    "\n",
    "    y_group_pred[i] = np.argmax(np.bincount(y_test_preds, minlength = 2))\n",
    "\n",
    "    y_group_true[i] = np.argmax(np.bincount(y_test, minlength = 2))\n",
    "\n",
    "    # metricas sin considerar grupos\n",
    "    test_metrics[i] = accuracy_score(y_pred=y_test_preds, \n",
    "                                        y_true=y_test)\n",
    "                        #  precision_score(y_pred=y_test_preds, \n",
    "                        #                  y_true=y_test),\n",
    "                        #  recall_score(y_pred=y_test_preds, \n",
    "                        #               y_true=y_test),\n",
    "                        # specificity_score(y_pred=y_test_preds, \n",
    "                        #                    y_true=y_test)\n",
    "                                        #    ]\n",
    "    print(f\"********************** iteracion {i + 1} **********************\")\n",
    "    \n",
    "    # limpiamos la sesion\n",
    "    del(modelo, trained_model, X_train, y_train, X_test, y_test, X_train_scaled, X_test_scaled)\n",
    "    tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(y_group_true == y_group_pred))\n",
    "print(accuracy_score(y_pred=y_group_pred, y_true=y_group_true))\n",
    "print(precision_score(y_pred=y_group_pred, y_true=y_group_true))\n",
    "print(recall_score(y_pred=y_group_pred, y_true=y_group_true))\n",
    "print(specificity_score(y_pred=y_group_pred, y_true=y_group_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "hombres = y_group_true[np.where(sex == 0)]\n",
    "mujeres = y_group_true[np.where(sex == 1)]\n",
    "\n",
    "hombres_preds = y_group_pred[np.where(sex == 0)]\n",
    "mujeres_preds = y_group_pred[np.where(sex == 1)]\n",
    "\n",
    "print(accuracy_score(y_pred=hombres_preds, y_true=hombres))\n",
    "print(accuracy_score(y_pred=mujeres_preds,  y_true=mujeres))\n",
    "print(precision_score(y_pred=hombres_preds, y_true=hombres))\n",
    "print(precision_score(y_pred=mujeres_preds, y_true=mujeres))\n",
    "print(recall_score(y_pred=hombres_preds, y_true=hombres))\n",
    "print(recall_score(y_pred=mujeres_preds, y_true=mujeres))\n",
    "print(specificity_score(y_pred=hombres_preds, y_true=hombres))\n",
    "print(specificity_score(y_pred=mujeres_preds, y_true=mujeres))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
